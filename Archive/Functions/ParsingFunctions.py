def model_performance(
    results: dict, header: tuple = None
) -> tuple[list[dict, dict, dict, dict], list[str, list[dict, dict, dict, dict]]]:
    """
    Takes in the Dictionary given by 'EVAL' in ibmfl and returns a tuple of

    (loss: float,
    accuracy: float,
    params: tuple of floats,)

    The params maybe unspecifed, or can be changed by specifying the order as a tuple of strings
    """
    if not header:
        header = (
            "precision micro",
            "precision macro",
            "precision weighted",
            "recall micro",
            "recall macro",
            "recall weighted",
            "f1 micro",
            "f1 macro",
            "f1 weighted",
        )

    return (
        results["loss"],
        results["accuracy"],
        tuple(results[param] for param in header),
    )


def get_sar_data_pi(sarfile_path) -> tuple[list, list]:
    """
    Gets data from the files generated by SAR.

    Give the path to the SAR file as the input.

    Return value is as follows :

    It returns a tuple with 2 lists

    The first list contains 4 dicts with the average values for CPU, MEMORY, DISK and NET.
    The keys to the values are whatever titles SAR gave them.

    The second list contains two elements. First being a string value which is the timestamp and the second
    is a list with 4 dicts like before.
    """
    with open(sarfile_path) as f:
        if not f.read().strip():
            raise ValueError

    with open(sarfile_path) as f:
        results = []

        f.readline()
        f.readline()  # Skips the first two lines which aren't useful

        # Each set of stats has its entries put into a list in the following order

        #  0    1     2      3
        # CPU MEMORY DISK NETWORK (All of these are dictionaries)

        # The Timestamp for all the Data values (NOT THE TIMESTAMP FOR HEADERS) is the first element of the list, the second element is a list containing CPU, MEM, DISK and NET
        # The keys of CPU/MEM/DISK/NETWORK are whatever title SAR gave them.

        # * TL;DR
        # * We make 4 dictionaries for CPU MEM DISK and NETWORK with keys being the title of each and values being the actual value
        # * We put these into a list. We put this list as a second element to another list, the first element of which is the timestamp

        # ! Begin Looping for SAR Data
        while True:
            cpuh = f.readline().split()
            # If both lines are empty, this means the average values are next. Lets break the loop
            if len(cpuh) == 0:
                break

            cpud = f.readline().split()

            f.readline()  # Skip the extra line thats in between each two sets of values
            memh = f.readline().split()
            memd = f.readline().split()
            f.readline()
            diskh = f.readline().split()
            diskd = f.readline().split()
            f.readline()
            neth = f.readline().split()
            netd = f.readline().split()
            f.readline()

            timestamp = cpud[0]

            CPU = {cpuh[i]: cpud[i] for i in range(1, len(cpuh))}
            MEM = {memh[i]: memd[i] for i in range(1, len(memh))}
            DISK = {diskh[i]: diskd[i] for i in range(1, len(diskh))}
            NET = {neth[i]: netd[i] for i in range(1, len(neth))}
            results.append([timestamp, [CPU, MEM, DISK, NET]])

        # ! Read the averages
        cpuh = f.readline().split()
        cpud = f.readline().split()
        f.readline()  # Skip the extra line thats in between each two sets of values
        memh = f.readline().split()
        memd = f.readline().split()
        f.readline()
        diskh = f.readline().split()
        diskd = f.readline().split()
        f.readline()
        neth = f.readline().split()
        netd = f.readline().split()
        f.readline()

        CPU = {cpuh[i]: cpud[i] for i in range(1, len(cpuh))}
        MEM = {memh[i]: memd[i] for i in range(1, len(memh))}
        DISK = {diskh[i]: diskd[i] for i in range(1, len(diskh))}
        NET = {neth[i]: netd[i] for i in range(1, len(neth))}

        return ([CPU, MEM, DISK, NET], results)


def get_power_data(power_file_path) -> dict:
    import pickle

    results = {}
    f = open(power_file_path, "rb")
    while True:
        try:
            data: dict = pickle.load(f)
            results.update(data)
        except EOFError:
            break
        except Exception as e:
            print(e)
    f.close()
    return results
